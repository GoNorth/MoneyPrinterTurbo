import glob
import itertools
import os
import random
import gc
import shutil
import subprocess
import platform
from typing import List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from loguru import logger
from moviepy import (
    AudioFileClip,
    ColorClip,
    CompositeAudioClip,
    CompositeVideoClip,
    ImageClip,
    TextClip,
    VideoFileClip,
    afx,
    concatenate_videoclips,
)
from moviepy.video.tools.subtitles import SubtitlesClip
from PIL import ImageFont

from app.models import const
from app.models.schema import (
    MaterialInfo,
    VideoAspect,
    VideoConcatMode,
    VideoParams,
    VideoTransitionMode,
)
from app.services.utils import video_effects
from app.utils import utils

class SubClippedVideoClip:
    def __init__(self, file_path, start_time=None, end_time=None, width=None, height=None, duration=None):
        self.file_path = file_path
        self.start_time = start_time
        self.end_time = end_time
        self.width = width
        self.height = height
        if duration is None:
            self.duration = end_time - start_time
        else:
            self.duration = duration

    def __str__(self):
        return f"SubClippedVideoClip(file_path={self.file_path}, start_time={self.start_time}, end_time={self.end_time}, duration={self.duration}, width={self.width}, height={self.height})"


audio_codec = "aac"
video_codec = "libx264"  # é»˜è®¤CPUç¼–ç å™¨ï¼Œä¼šåœ¨åˆå§‹åŒ–æ—¶æ ¹æ®GPUæ£€æµ‹ç»“æœæ›´æ–°
fps = 30

# GPUç¼–ç å™¨æ˜ å°„
GPU_ENCODERS = {
    "nvidia": "h264_nvenc",
    "intel": "h264_qsv",
    "amd": "h264_amf",
    "apple": "h264_videotoolbox",  # macOS
}

def check_nvidia_driver_version() -> bool:
    """
    æ£€æŸ¥NVIDIAé©±åŠ¨ç‰ˆæœ¬æ˜¯å¦æ”¯æŒNVENC
    éœ€è¦é©±åŠ¨ç‰ˆæœ¬ >= 570.0 (NVENC API 13.0)
    è¿”å›: True if supported, False otherwise
    """
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=driver_version", "--format=csv,noheader"],
            capture_output=True,
            text=True,
            timeout=2,
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
        )
        if result.returncode == 0 and result.stdout.strip():
            driver_version_str = result.stdout.strip().split(chr(10))[0]
            try:
                # æå–ä¸»ç‰ˆæœ¬å·ï¼ˆä¾‹å¦‚ "570.61" -> 570ï¼‰
                major_version = int(driver_version_str.split('.')[0])
                if major_version >= 570:
                    logger.debug(f"NVIDIAé©±åŠ¨ç‰ˆæœ¬: {driver_version_str} (æ”¯æŒNVENC)")
                    return True
                else:
                    logger.warning(f"NVIDIAé©±åŠ¨ç‰ˆæœ¬: {driver_version_str} (éœ€è¦ >= 570.0 æ‰èƒ½ä½¿ç”¨NVENC)")
                    return False
            except (ValueError, IndexError):
                logger.debug(f"æ— æ³•è§£æNVIDIAé©±åŠ¨ç‰ˆæœ¬: {driver_version_str}")
                return False
    except Exception as e:
        logger.debug(f"æ£€æŸ¥NVIDIAé©±åŠ¨ç‰ˆæœ¬å¤±è´¥: {str(e)}")
    
    return False

def detect_gpu() -> Optional[str]:
    """
    æ£€æµ‹å¯ç”¨çš„GPUç±»å‹
    è¿”å›: "nvidia", "intel", "amd", "apple" æˆ– None
    """
    try:
        system = platform.system().lower()
        
        # æ£€æµ‹NVIDIA GPU
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=name", "--format=csv,noheader"],
                capture_output=True,
                text=True,
                timeout=2,
                creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
            )
            if result.returncode == 0 and result.stdout.strip():
                gpu_name = result.stdout.strip().split(chr(10))[0]
                logger.info(f"æ£€æµ‹åˆ°NVIDIA GPU: {gpu_name}")
                # æ£€æŸ¥é©±åŠ¨ç‰ˆæœ¬æ˜¯å¦æ”¯æŒNVENC
                if check_nvidia_driver_version():
                    return "nvidia"
                else:
                    logger.warning("NVIDIAé©±åŠ¨ç‰ˆæœ¬è¿‡æ—§ï¼Œæ— æ³•ä½¿ç”¨NVENCç¡¬ä»¶åŠ é€Ÿ")
                    return None
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        # Windowsç³»ç»Ÿæ£€æµ‹Intel/AMD GPU
        if system == "windows":
            try:
                # æ£€æµ‹Intel GPU
                result = subprocess.run(
                    ["wmic", "path", "win32_VideoController", "get", "name"],
                    capture_output=True,
                    text=True,
                    timeout=2,
                    creationflags=subprocess.CREATE_NO_WINDOW
                )
                if result.returncode == 0:
                    output = result.stdout.lower()
                    if "intel" in output and ("uhd" in output or "iris" in output or "xe" in output):
                        logger.info("æ£€æµ‹åˆ°Intel GPU")
                        return "intel"
                    if "amd" in output or "radeon" in output:
                        logger.info("æ£€æµ‹åˆ°AMD GPU")
                        return "amd"
            except (FileNotFoundError, subprocess.TimeoutExpired):
                pass
        
        # macOSæ£€æµ‹Apple Silicon
        if system == "darwin":
            try:
                result = subprocess.run(
                    ["system_profiler", "SPDisplaysDataType"],
                    capture_output=True,
                    text=True,
                    timeout=2
                )
                if result.returncode == 0 and "Apple" in result.stdout:
                    logger.info("æ£€æµ‹åˆ°Apple GPU")
                    return "apple"
            except (FileNotFoundError, subprocess.TimeoutExpired):
                pass
        
        # Linuxæ£€æµ‹ï¼ˆå¯é€‰ï¼‰
        if system == "linux":
            try:
                # æ£€æµ‹Intel
                if os.path.exists("/sys/class/drm/card0/device/vendor"):
                    with open("/sys/class/drm/card0/device/vendor", "r") as f:
                        vendor_id = f.read().strip()
                        if vendor_id == "0x8086":  # Intel
                            logger.info("æ£€æµ‹åˆ°Intel GPU")
                            return "intel"
                        elif vendor_id == "0x1002":  # AMD
                            logger.info("æ£€æµ‹åˆ°AMD GPU")
                            return "amd"
            except Exception:
                pass
        
    except Exception as e:
        logger.debug(f"GPUæ£€æµ‹å¤±è´¥: {str(e)}")
    
    return None

def check_ffmpeg_encoder_support(encoder_name: str) -> bool:
    """
    æ£€æŸ¥FFmpegæ˜¯å¦æ”¯æŒæŒ‡å®šçš„ç¼–ç å™¨
    """
    try:
        # è·å–FFmpegè·¯å¾„
        ffmpeg_exe = os.environ.get("IMAGEIO_FFMPEG_EXE", "ffmpeg")
        if not os.path.isfile(ffmpeg_exe):
            ffmpeg_exe = "ffmpeg"
        
        result = subprocess.run(
            [ffmpeg_exe, "-encoders"],
            capture_output=True,
            text=True,
            timeout=5,
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
        )
        
        if result.returncode == 0:
            return encoder_name in result.stdout
    except Exception as e:
        logger.debug(f"æ£€æŸ¥FFmpegç¼–ç å™¨æ”¯æŒå¤±è´¥: {str(e)}")
    
    return False

def check_ffmpeg_filter_support(filter_name: str) -> bool:
    """
    æ£€æŸ¥FFmpegæ˜¯å¦æ”¯æŒæŒ‡å®šçš„æ»¤é•œ
    """
    try:
        # è·å–FFmpegè·¯å¾„
        ffmpeg_exe = os.environ.get("IMAGEIO_FFMPEG_EXE", "ffmpeg")
        if not os.path.isfile(ffmpeg_exe):
            ffmpeg_exe = "ffmpeg"
        
        result = subprocess.run(
            [ffmpeg_exe, "-filters"],
            capture_output=True,
            text=True,
            timeout=5,
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
        )
        
        if result.returncode == 0:
            return filter_name in result.stdout
    except Exception as e:
        logger.debug(f"æ£€æŸ¥FFmpegæ»¤é•œæ”¯æŒå¤±è´¥: {str(e)}")
    
    return False

def get_gpu_scale_filter(gpu_type: Optional[str]) -> Optional[str]:
    """
    æ ¹æ®GPUç±»å‹è¿”å›å¯¹åº”çš„GPUç¼©æ”¾æ»¤é•œ
    è¿”å›: æ»¤é•œåç§°æˆ–Noneï¼ˆä½¿ç”¨CPUç¼©æ”¾ï¼‰
    """
    if not gpu_type:
        return None
    
    gpu_filters = {
        "nvidia": "scale_npp",  # NVIDIA GPUç¼©æ”¾
        "intel": "scale_qsv",   # Intel GPUç¼©æ”¾
        "amd": "scale",          # AMDæš‚ä¸æ”¯æŒGPUç¼©æ”¾ï¼Œä½¿ç”¨CPU
        "apple": "scale",        # Appleæš‚ä¸æ”¯æŒGPUç¼©æ”¾ï¼Œä½¿ç”¨CPU
    }
    
    filter_name = gpu_filters.get(gpu_type)
    if filter_name and filter_name != "scale":
        # æ£€æŸ¥FFmpegæ˜¯å¦æ”¯æŒè¯¥GPUæ»¤é•œ
        if check_ffmpeg_filter_support(filter_name):
            logger.debug(f"âœ… æ£€æµ‹åˆ°GPUç¼©æ”¾æ»¤é•œæ”¯æŒ: {filter_name}")
            return filter_name
        else:
            logger.debug(f"âš ï¸ GPUç¼©æ”¾æ»¤é•œ {filter_name} ä¸æ”¯æŒï¼Œå›é€€åˆ°CPUç¼©æ”¾")
    
    return None

# å…¨å±€å˜é‡ï¼šç¼“å­˜GPUç±»å‹å’Œç¼©æ”¾æ»¤é•œ
_cached_gpu_type = None
_cached_scale_filter = None

def get_gpu_scale_filter_cached() -> Optional[str]:
    """
    è·å–GPUç¼©æ”¾æ»¤é•œï¼ˆå¸¦ç¼“å­˜ï¼‰
    """
    global _cached_gpu_type, _cached_scale_filter
    
    if _cached_scale_filter is None:
        if _cached_gpu_type is None:
            _cached_gpu_type = detect_gpu()
        _cached_scale_filter = get_gpu_scale_filter(_cached_gpu_type)
        if _cached_scale_filter:
            logger.info(f"âœ… ä½¿ç”¨GPUç¼©æ”¾: {_cached_scale_filter}")
        else:
            logger.info("â„¹ï¸ ä½¿ç”¨CPUç¼©æ”¾")
    
    return _cached_scale_filter

def get_best_video_codec() -> Tuple[str, str]:
    """
    è‡ªåŠ¨é€‰æ‹©æœ€ä½³çš„è§†é¢‘ç¼–ç å™¨
    è¿”å›: (ç¼–ç å™¨åç§°, æè¿°ä¿¡æ¯)
    """
    gpu_type = detect_gpu()
    
    if gpu_type and gpu_type in GPU_ENCODERS:
        encoder = GPU_ENCODERS[gpu_type]
        if check_ffmpeg_encoder_support(encoder):
            gpu_names = {
                "nvidia": "NVIDIA GPU",
                "intel": "Intel GPU",
                "amd": "AMD GPU",
                "apple": "Apple GPU"
            }
            logger.info(f"âœ… ä½¿ç”¨GPUç¡¬ä»¶åŠ é€Ÿ: {encoder} ({gpu_names[gpu_type]})")
            return encoder, f"{encoder} ({gpu_names[gpu_type]})"
        else:
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°{gpu_type.upper()} GPUï¼Œä½†FFmpegä¸æ”¯æŒ{encoder}ï¼Œå›é€€åˆ°CPUç¼–ç ")
    
    logger.info("â„¹ï¸ ä½¿ç”¨CPUç¼–ç : libx264")
    return "libx264", "libx264 (CPU)"

def write_videofile_with_fallback(clip, filename, codec=None, fallback_codec="libx264", **kwargs):
    """
    å¸¦é”™è¯¯å›é€€çš„write_videofileåŒ…è£…å‡½æ•°
    å¦‚æœGPUç¼–ç å¤±è´¥ï¼Œè‡ªåŠ¨å›é€€åˆ°CPUç¼–ç 
    """
    if codec is None:
        codec = video_codec
    
    # å¦‚æœæ˜¯GPUç¼–ç å™¨ï¼Œå°è¯•ä½¿ç”¨ï¼Œå¤±è´¥åˆ™å›é€€
    if codec != fallback_codec and codec in GPU_ENCODERS.values():
        try:
            clip.write_videofile(filename, codec=codec, **kwargs)
            return
        except Exception as e:
            error_msg = str(e).lower()
            # æ£€æŸ¥æ˜¯å¦æ˜¯é©±åŠ¨ç‰ˆæœ¬æˆ–ç¼–ç å™¨ç›¸å…³çš„é”™è¯¯
            if any(keyword in error_msg for keyword in ["nvenc", "driver", "encoder", "not support", "invalid argument"]):
                logger.warning(f"âš ï¸ GPUç¼–ç å™¨ {codec} å¤±è´¥: {str(e)[:200]}")
                logger.info(f"ğŸ”„ è‡ªåŠ¨å›é€€åˆ°CPUç¼–ç : {fallback_codec}")
                # å›é€€åˆ°CPUç¼–ç 
                clip.write_videofile(filename, codec=fallback_codec, **kwargs)
                return
            else:
                # å…¶ä»–é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                raise
    
    # ç›´æ¥ä½¿ç”¨æŒ‡å®šç¼–ç å™¨ï¼ˆé€šå¸¸æ˜¯CPUç¼–ç ï¼‰
    clip.write_videofile(filename, codec=codec, **kwargs)

# åˆå§‹åŒ–æ—¶è‡ªåŠ¨æ£€æµ‹å¹¶è®¾ç½®æœ€ä½³ç¼–ç å™¨
_video_codec, _video_codec_desc = get_best_video_codec()
video_codec = _video_codec
logger.info(f"è§†é¢‘ç¼–ç å™¨å·²è®¾ç½®ä¸º: {_video_codec_desc}")

# åˆå§‹åŒ–æ—¶æ£€æµ‹GPUç¼©æ”¾æ»¤é•œ
get_gpu_scale_filter_cached()  # è§¦å‘æ£€æµ‹å¹¶ç¼“å­˜ç»“æœ

def resize_clip_with_gpu(
    input_path: str,
    output_path: str,
    target_width: int,
    target_height: int,
    gpu_scale_filter: Optional[str] = None,
    codec: str = None,
    fps: int = 30
) -> bool:
    """
    ä½¿ç”¨GPUæˆ–CPUç¼©æ”¾è§†é¢‘
    è¿”å›: True if success, False otherwise
    """
    try:
        # è·å–FFmpegè·¯å¾„
        ffmpeg_exe = os.environ.get("IMAGEIO_FFMPEG_EXE", "ffmpeg")
        if not os.path.isfile(ffmpeg_exe):
            ffmpeg_exe = "ffmpeg"
        
        if codec is None:
            codec = video_codec
        
        # æ„å»ºFFmpegå‘½ä»¤
        cmd = [
            ffmpeg_exe,
            "-i", input_path,
            "-vf", f"{gpu_scale_filter if gpu_scale_filter else 'scale'}={target_width}:{target_height}",
            "-c:v", codec,
            "-preset", "fast",
            "-crf", "23",
            "-r", str(fps),
            "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
        )
        
        if result.returncode == 0 and os.path.exists(output_path):
            return True
        else:
            logger.warning(f"GPUç¼©æ”¾å¤±è´¥: {result.stderr[:200] if result.stderr else 'unknown error'}")
            return False
    except Exception as e:
        logger.warning(f"GPUç¼©æ”¾å¼‚å¸¸: {str(e)}")
        return False

def close_clip(clip):
    if clip is None:
        return
        
    try:
        # close main resources
        if hasattr(clip, 'reader') and clip.reader is not None:
            clip.reader.close()
            
        # close audio resources
        if hasattr(clip, 'audio') and clip.audio is not None:
            if hasattr(clip.audio, 'reader') and clip.audio.reader is not None:
                clip.audio.reader.close()
            del clip.audio
            
        # close mask resources
        if hasattr(clip, 'mask') and clip.mask is not None:
            if hasattr(clip.mask, 'reader') and clip.mask.reader is not None:
                clip.mask.reader.close()
            del clip.mask
            
        # handle child clips in composite clips
        if hasattr(clip, 'clips') and clip.clips:
            for child_clip in clip.clips:
                if child_clip is not clip:  # avoid possible circular references
                    close_clip(child_clip)
            
        # clear clip list
        if hasattr(clip, 'clips'):
            clip.clips = []
            
    except Exception as e:
        logger.error(f"failed to close clip: {str(e)}")
    
    del clip
    gc.collect()

def delete_files(files: List[str] | str):
    if isinstance(files, str):
        files = [files]
        
    for file in files:
        try:
            os.remove(file)
        except:
            pass

def get_bgm_file(bgm_type: str = "random", bgm_file: str = ""):
    if not bgm_type:
        return ""

    if bgm_file and os.path.exists(bgm_file):
        return bgm_file

    if bgm_type == "random":
        suffix = "*.mp3"
        song_dir = utils.song_dir()
        files = glob.glob(os.path.join(song_dir, suffix))
        return random.choice(files)

    return ""


def process_single_clip(
    subclipped_item: SubClippedVideoClip,
    clip_index: int,
    video_width: int,
    video_height: int,
    output_dir: str,
    max_clip_duration: int,
    video_transition_mode: VideoTransitionMode,
    gpu_scale_filter: Optional[str] = None,
) -> Optional[SubClippedVideoClip]:
    """
    å¤„ç†å•ä¸ªclipï¼šåŠ è½½ã€ç¼©æ”¾ã€æ·»åŠ è½¬åœºæ•ˆæœã€å†™å…¥æ–‡ä»¶
    è¿”å›: å¤„ç†åçš„SubClippedVideoClipæˆ–Noneï¼ˆå¤±è´¥æ—¶ï¼‰
    """
    try:
        logger.debug(f"processing clip {clip_index+1}: {subclipped_item.width}x{subclipped_item.height}")
        
        # 1. åŠ è½½è§†é¢‘
        clip = VideoFileClip(subclipped_item.file_path).subclipped(
            subclipped_item.start_time, 
            subclipped_item.end_time
        )
        clip_duration = clip.duration
        clip_w, clip_h = clip.size
        
        # 2. ç¼©æ”¾å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        needs_resize = clip_w != video_width or clip_h != video_height
        temp_resized_path = None
        gpu_resize_success = False
        
        if needs_resize:
            clip_ratio = clip.w / clip.h
            video_ratio = video_width / video_height
            logger.debug(f"resizing clip {clip_index+1}, source: {clip_w}x{clip_h}, ratio: {clip_ratio:.2f}, target: {video_width}x{video_height}, ratio: {video_ratio:.2f}")
            
            # å°è¯•ä½¿ç”¨GPUç¼©æ”¾ï¼ˆä»…å½“å®½é«˜æ¯”ç›¸åŒæ—¶ï¼ŒGPUç¼©æ”¾æ›´ç®€å•é«˜æ•ˆï¼‰
            if gpu_scale_filter and clip_ratio == video_ratio:
                temp_resized_path = f"{output_dir}/temp-resized-{clip_index+1}.mp4"
                # å…ˆä¿å­˜åŸå§‹clipåˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆå› ä¸ºGPUç¼©æ”¾éœ€è¦æ–‡ä»¶è¾“å…¥ï¼‰
                temp_input_path = f"{output_dir}/temp-input-{clip_index+1}.mp4"
                try:
                    # ä½¿ç”¨å¿«é€Ÿç¼–ç ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    clip.write_videofile(
                        temp_input_path,
                        codec="libx264",
                        preset="ultrafast",
                        logger=None,
                        fps=fps,
                        audio=False
                    )
                    
                    if os.path.exists(temp_input_path):
                        if resize_clip_with_gpu(
                            temp_input_path,
                            temp_resized_path,
                            video_width,
                            video_height,
                            gpu_scale_filter,
                            codec=video_codec,
                            fps=fps
                        ) and os.path.exists(temp_resized_path):
                            # GPUç¼©æ”¾æˆåŠŸï¼Œé‡æ–°åŠ è½½ç¼©æ”¾åçš„è§†é¢‘
                            close_clip(clip)
                            clip = VideoFileClip(temp_resized_path)
                            clip_w, clip_h = clip.size
                            gpu_resize_success = True
                            logger.debug(f"âœ… clip {clip_index+1} GPUç¼©æ”¾æˆåŠŸ")
                except Exception as e:
                    logger.debug(f"GPUç¼©æ”¾å¤±è´¥ï¼Œå›é€€åˆ°CPU: {str(e)[:100]}")
                finally:
                    # æ¸…ç†ä¸´æ—¶è¾“å…¥æ–‡ä»¶
                    try:
                        if os.path.exists(temp_input_path):
                            os.remove(temp_input_path)
                    except:
                        pass
            
            # å¦‚æœGPUç¼©æ”¾å¤±è´¥æˆ–æœªä½¿ç”¨GPUï¼Œä½¿ç”¨MoviePy CPUç¼©æ”¾
            if not gpu_resize_success:
                if clip_ratio == video_ratio:
                    clip = clip.resized(new_size=(video_width, video_height))
                else:
                    if clip_ratio > video_ratio:
                        scale_factor = video_width / clip_w
                    else:
                        scale_factor = video_height / clip_h

                    new_width = int(clip_w * scale_factor)
                    new_height = int(clip_h * scale_factor)

                    background = ColorClip(size=(video_width, video_height), color=(0, 0, 0)).with_duration(clip_duration)
                    clip_resized = clip.resized(new_size=(new_width, new_height)).with_position("center")
                    clip = CompositeVideoClip([background, clip_resized])
        
        # 3. æ·»åŠ è½¬åœºæ•ˆæœ
        shuffle_side = random.choice(["left", "right", "top", "bottom"])
        if video_transition_mode.value == VideoTransitionMode.none.value:
            pass  # ä¸æ·»åŠ è½¬åœº
        elif video_transition_mode.value == VideoTransitionMode.fade_in.value:
            clip = video_effects.fadein_transition(clip, 1)
        elif video_transition_mode.value == VideoTransitionMode.fade_out.value:
            clip = video_effects.fadeout_transition(clip, 1)
        elif video_transition_mode.value == VideoTransitionMode.slide_in.value:
            clip = video_effects.slidein_transition(clip, 1, shuffle_side)
        elif video_transition_mode.value == VideoTransitionMode.slide_out.value:
            clip = video_effects.slideout_transition(clip, 1, shuffle_side)
        elif video_transition_mode.value == VideoTransitionMode.shuffle.value:
            transition_funcs = [
                lambda c: video_effects.fadein_transition(c, 1),
                lambda c: video_effects.fadeout_transition(c, 1),
                lambda c: video_effects.slidein_transition(c, 1, shuffle_side),
                lambda c: video_effects.slideout_transition(c, 1, shuffle_side),
            ]
            shuffle_transition = random.choice(transition_funcs)
            clip = shuffle_transition(clip)

        # 4. è£å‰ªåˆ°æœ€å¤§æ—¶é•¿
        if clip.duration > max_clip_duration:
            clip = clip.subclipped(0, max_clip_duration)
        
        # 5. å†™å…¥ä¸´æ—¶æ–‡ä»¶
        clip_file = f"{output_dir}/temp-clip-{clip_index+1}.mp4"
        write_videofile_with_fallback(clip, clip_file, codec=video_codec, logger=None, fps=fps)
        
        # 6. æ¸…ç†èµ„æº
        close_clip(clip)
        if temp_resized_path and os.path.exists(temp_resized_path):
            try:
                os.remove(temp_resized_path)
            except:
                pass
        
        # 7. è¿”å›å¤„ç†ç»“æœ
        return SubClippedVideoClip(
            file_path=clip_file,
            duration=clip_duration if clip_duration <= max_clip_duration else max_clip_duration,
            width=clip_w,
            height=clip_h
        )
        
    except Exception as e:
        logger.error(f"failed to process clip {clip_index+1}: {str(e)}")
        return None


def combine_videos(
    combined_video_path: str,
    video_paths: List[str],
    audio_file: str,
    video_aspect: VideoAspect = VideoAspect.portrait,
    video_concat_mode: VideoConcatMode = VideoConcatMode.random,
    video_transition_mode: VideoTransitionMode = None,
    max_clip_duration: int = 5,
    threads: int = 2,
) -> str:
    audio_clip = AudioFileClip(audio_file)
    audio_duration = audio_clip.duration
    logger.info(f"audio duration: {audio_duration} seconds")
    # Required duration of each clip
    req_dur = audio_duration / len(video_paths)
    req_dur = max_clip_duration
    logger.info(f"maximum clip duration: {req_dur} seconds")
    output_dir = os.path.dirname(combined_video_path)

    aspect = VideoAspect(video_aspect)
    video_width, video_height = aspect.to_resolution()

    processed_clips = []
    subclipped_items = []
    video_duration = 0
    for video_path in video_paths:
        clip = VideoFileClip(video_path)
        clip_duration = clip.duration
        clip_w, clip_h = clip.size
        close_clip(clip)
        
        start_time = 0

        while start_time < clip_duration:
            end_time = min(start_time + max_clip_duration, clip_duration)            
            if clip_duration - start_time >= max_clip_duration:
                subclipped_items.append(SubClippedVideoClip(file_path= video_path, start_time=start_time, end_time=end_time, width=clip_w, height=clip_h))
            start_time = end_time    
            if video_concat_mode.value == VideoConcatMode.sequential.value:
                break

    # random subclipped_items order
    if video_concat_mode.value == VideoConcatMode.random.value:
        random.shuffle(subclipped_items)
    
    # If using original aspect ratio, use the first clip's resolution as target
    if video_width is None or video_height is None:
        if subclipped_items:
            video_width = subclipped_items[0].width
            video_height = subclipped_items[0].height
            logger.info(f"using original aspect ratio: {video_width}x{video_height} (from first clip)")
        else:
            # Fallback to portrait if no clips available
            video_width, video_height = 1080, 1920
            logger.warning("no clips available, using default resolution 1080x1920")
        
    logger.debug(f"total subclipped items: {len(subclipped_items)}")
    
    # è·å–GPUç¼©æ”¾æ»¤é•œï¼ˆå¦‚æœæ”¯æŒï¼‰
    gpu_scale_filter = get_gpu_scale_filter_cached()
    
    # å¹¶è¡Œå¤„ç†clips
    # é™åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…å†…å­˜æº¢å‡ºï¼ˆä½¿ç”¨CPUæ ¸å¿ƒæ•°ï¼Œä½†è‡³å°‘ä¸º1ï¼Œæœ€å¤šä¸è¶…è¿‡clipæ•°é‡ï¼‰
    max_workers = min(len(subclipped_items), max(1, os.cpu_count() or 4))
    logger.info(f"ğŸš€ ä½¿ç”¨å¹¶è¡Œå¤„ç†: {max_workers} ä¸ªworkerå¤„ç† {len(subclipped_items)} ä¸ªclips")
    
    # ç­›é€‰éœ€è¦å¤„ç†çš„clipsï¼ˆæ ¹æ®éŸ³é¢‘æ—¶é•¿ï¼‰
    clips_to_process = []
    for i, subclipped_item in enumerate(subclipped_items):
        if video_duration > audio_duration:
            break
        clips_to_process.append((i, subclipped_item))
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    processed_clips_dict = {}  # ä½¿ç”¨å­—å…¸ä¿æŒé¡ºåº
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_index = {
            executor.submit(
                process_single_clip,
                subclipped_item,
                i,
                video_width,
                video_height,
                output_dir,
                max_clip_duration,
                video_transition_mode,
                gpu_scale_filter,
            ): i
            for i, subclipped_item in clips_to_process
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_index):
            i = future_to_index[future]
            try:
                result = future.result()
                if result:
                    processed_clips_dict[i] = result
                    video_duration += result.duration
                    logger.debug(f"âœ… clip {i+1} å¤„ç†å®Œæˆ, duration: {result.duration:.2f}s, total: {video_duration:.2f}s")
                else:
                    logger.warning(f"âš ï¸ clip {i+1} å¤„ç†å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ clip {i+1} å¤„ç†å¼‚å¸¸: {str(e)}")
    
    # æŒ‰ç´¢å¼•æ’åºï¼Œä¿æŒåŸå§‹é¡ºåº
    processed_clips = [processed_clips_dict[i] for i in sorted(processed_clips_dict.keys())]
    
    # loop processed clips until the video duration matches or exceeds the audio duration.
    if video_duration < audio_duration:
        logger.warning(f"video duration ({video_duration:.2f}s) is shorter than audio duration ({audio_duration:.2f}s), looping clips to match audio length.")
        base_clips = processed_clips.copy()
        for clip in itertools.cycle(base_clips):
            if video_duration >= audio_duration:
                break
            processed_clips.append(clip)
            video_duration += clip.duration
        logger.info(f"video duration: {video_duration:.2f}s, audio duration: {audio_duration:.2f}s, looped {len(processed_clips)-len(base_clips)} clips")
     
    # merge video clips progressively, avoid loading all videos at once to avoid memory overflow
    logger.info("starting clip merging process")
    if not processed_clips:
        logger.warning("no clips available for merging")
        return combined_video_path
    
    # if there is only one clip, use it directly
    if len(processed_clips) == 1:
        logger.info("using single clip directly")
        shutil.copy(processed_clips[0].file_path, combined_video_path)
        delete_files(processed_clips)
        logger.info("video combining completed")
        return combined_video_path
    
    # create initial video file as base
    base_clip_path = processed_clips[0].file_path
    temp_merged_video = f"{output_dir}/temp-merged-video.mp4"
    temp_merged_next = f"{output_dir}/temp-merged-next.mp4"
    
    # copy first clip as initial merged video
    shutil.copy(base_clip_path, temp_merged_video)
    
    # merge remaining video clips one by one
    for i, clip in enumerate(processed_clips[1:], 1):
        logger.info(f"merging clip {i}/{len(processed_clips)-1}, duration: {clip.duration:.2f}s")
        
        try:
            # load current base video and next clip to merge
            base_clip = VideoFileClip(temp_merged_video)
            next_clip = VideoFileClip(clip.file_path)
            
            # merge these two clips
            merged_clip = concatenate_videoclips([base_clip, next_clip])

            # save merged result to temp file
            write_videofile_with_fallback(
                merged_clip,
                filename=temp_merged_next,
                codec=video_codec,
                threads=threads,
                logger=None,
                temp_audiofile_path=output_dir,
                audio_codec=audio_codec,
                fps=fps,
            )
            close_clip(base_clip)
            close_clip(next_clip)
            close_clip(merged_clip)
            
            # replace base file with new merged file
            delete_files(temp_merged_video)
            os.rename(temp_merged_next, temp_merged_video)
            
        except Exception as e:
            logger.error(f"failed to merge clip: {str(e)}")
            continue
    
    # after merging, rename final result to target file name
    os.rename(temp_merged_video, combined_video_path)
    
    # clean temp files
    clip_files = [clip.file_path for clip in processed_clips]
    delete_files(clip_files)
            
    logger.info("video combining completed")
    return combined_video_path


def wrap_text(text, max_width, font="Arial", fontsize=60):
    # Create ImageFont
    font = ImageFont.truetype(font, fontsize)

    def get_text_size(inner_text):
        inner_text = inner_text.strip()
        left, top, right, bottom = font.getbbox(inner_text)
        return right - left, bottom - top

    width, height = get_text_size(text)
    if width <= max_width:
        return text, height

    processed = True

    _wrapped_lines_ = []
    words = text.split(" ")
    _txt_ = ""
    for word in words:
        _before = _txt_
        _txt_ += f"{word} "
        _width, _height = get_text_size(_txt_)
        if _width <= max_width:
            continue
        else:
            if _txt_.strip() == word.strip():
                processed = False
                break
            _wrapped_lines_.append(_before)
            _txt_ = f"{word} "
    _wrapped_lines_.append(_txt_)
    if processed:
        _wrapped_lines_ = [line.strip() for line in _wrapped_lines_]
        result = "\n".join(_wrapped_lines_).strip()
        height = len(_wrapped_lines_) * height
        return result, height

    _wrapped_lines_ = []
    chars = list(text)
    _txt_ = ""
    for word in chars:
        _txt_ += word
        _width, _height = get_text_size(_txt_)
        if _width <= max_width:
            continue
        else:
            _wrapped_lines_.append(_txt_)
            _txt_ = ""
    _wrapped_lines_.append(_txt_)
    result = "\n".join(_wrapped_lines_).strip()
    height = len(_wrapped_lines_) * height
    return result, height


def generate_video(
    video_path: str,
    audio_path: str,
    subtitle_path: str,
    output_file: str,
    params: VideoParams,
):
    aspect = VideoAspect(params.video_aspect)
    video_width, video_height = aspect.to_resolution()
    
    # If using original aspect ratio, get resolution from the input video
    if video_width is None or video_height is None:
        input_clip = VideoFileClip(video_path)
        video_width, video_height = input_clip.size
        close_clip(input_clip)
        logger.info(f"using original aspect ratio: {video_width} x {video_height} (from input video)")

    logger.info(f"generating video: {video_width} x {video_height}")
    logger.info(f"  â‘  video: {video_path}")
    logger.info(f"  â‘¡ audio: {audio_path}")
    logger.info(f"  â‘¢ subtitle: {subtitle_path}")
    logger.info(f"  â‘£ output: {output_file}")

    # https://github.com/harry0703/MoneyPrinterTurbo/issues/217
    # PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'final-1.mp4.tempTEMP_MPY_wvf_snd.mp3'
    # write into the same directory as the output file
    output_dir = os.path.dirname(output_file)

    font_path = ""
    if params.subtitle_enabled:
        if not params.font_name:
            params.font_name = "STHeitiMedium.ttc"
        font_path = os.path.join(utils.font_dir(), params.font_name)
        if os.name == "nt":
            font_path = font_path.replace("\\", "/")

        logger.info(f"  â‘¤ font: {font_path}")

    def create_text_clip(subtitle_item):
        params.font_size = int(params.font_size)
        params.stroke_width = int(params.stroke_width)
        phrase = subtitle_item[1]
        max_width = video_width * 0.9
        wrapped_txt, txt_height = wrap_text(
            phrase, max_width=max_width, font=font_path, fontsize=params.font_size
        )
        interline = int(params.font_size * 0.25)
        size=(int(max_width), int(txt_height + params.font_size * 0.25 + (interline * (wrapped_txt.count("\n") + 1))))

        _clip = TextClip(
            text=wrapped_txt,
            font=font_path,
            font_size=params.font_size,
            color=params.text_fore_color,
            bg_color=params.text_background_color,
            stroke_color=params.stroke_color,
            stroke_width=params.stroke_width,
            # interline=interline,
            # size=size,
        )
        duration = subtitle_item[0][1] - subtitle_item[0][0]
        _clip = _clip.with_start(subtitle_item[0][0])
        _clip = _clip.with_end(subtitle_item[0][1])
        _clip = _clip.with_duration(duration)
        if params.subtitle_position == "bottom":
            _clip = _clip.with_position(("center", video_height * 0.95 - _clip.h))
        elif params.subtitle_position == "top":
            _clip = _clip.with_position(("center", video_height * 0.05))
        elif params.subtitle_position == "custom":
            # Ensure the subtitle is fully within the screen bounds
            margin = 10  # Additional margin, in pixels
            max_y = video_height - _clip.h - margin
            min_y = margin
            custom_y = (video_height - _clip.h) * (params.custom_position / 100)
            custom_y = max(
                min_y, min(custom_y, max_y)
            )  # Constrain the y value within the valid range
            _clip = _clip.with_position(("center", custom_y))
        else:  # center
            _clip = _clip.with_position(("center", "center"))
        return _clip

    video_clip = VideoFileClip(video_path).without_audio()
    audio_clip = AudioFileClip(audio_path).with_effects(
        [afx.MultiplyVolume(params.voice_volume)]
    )

    def make_textclip(text):
        return TextClip(
            text=text,
            font=font_path,
            font_size=params.font_size,
        )

    if subtitle_path and os.path.exists(subtitle_path):
        sub = SubtitlesClip(
            subtitles=subtitle_path, encoding="utf-8", make_textclip=make_textclip
        )
        text_clips = []
        for item in sub.subtitles:
            clip = create_text_clip(subtitle_item=item)
            text_clips.append(clip)
        video_clip = CompositeVideoClip([video_clip, *text_clips])

    bgm_file = get_bgm_file(bgm_type=params.bgm_type, bgm_file=params.bgm_file)
    if bgm_file:
        try:
            bgm_clip = AudioFileClip(bgm_file).with_effects(
                [
                    afx.MultiplyVolume(params.bgm_volume),
                    afx.AudioFadeOut(3),
                    afx.AudioLoop(duration=video_clip.duration),
                ]
            )
            audio_clip = CompositeAudioClip([audio_clip, bgm_clip])
        except Exception as e:
            logger.error(f"failed to add bgm: {str(e)}")

    video_clip = video_clip.with_audio(audio_clip)
    write_videofile_with_fallback(
        video_clip,
        output_file,
        codec=video_codec,
        audio_codec=audio_codec,
        temp_audiofile_path=output_dir,
        threads=params.n_threads or 2,
        logger=None,
        fps=fps,
    )
    video_clip.close()
    del video_clip


def preprocess_video(materials: List[MaterialInfo], clip_duration=4):
    for material in materials:
        if not material.url:
            continue

        ext = utils.parse_extension(material.url)
        try:
            clip = VideoFileClip(material.url)
        except Exception:
            clip = ImageClip(material.url)

        width = clip.size[0]
        height = clip.size[1]
        if width < 480 or height < 480:
            logger.warning(f"low resolution material: {width}x{height}, minimum 480x480 required")
            continue

        if ext in const.FILE_TYPE_IMAGES:
            logger.info(f"processing image: {material.url}")
            # Create an image clip and set its duration to 3 seconds
            clip = (
                ImageClip(material.url)
                .with_duration(clip_duration)
                .with_position("center")
            )
            # Apply a zoom effect using the resize method.
            # A lambda function is used to make the zoom effect dynamic over time.
            # The zoom effect starts from the original size and gradually scales up to 120%.
            # t represents the current time, and clip.duration is the total duration of the clip (3 seconds).
            # Note: 1 represents 100% size, so 1.2 represents 120% size.
            zoom_clip = clip.resized(
                lambda t: 1 + (clip_duration * 0.03) * (t / clip.duration)
            )

            # Optionally, create a composite video clip containing the zoomed clip.
            # This is useful when you want to add other elements to the video.
            final_clip = CompositeVideoClip([zoom_clip])

            # Output the video to a file.
            video_file = f"{material.url}.mp4"
            write_videofile_with_fallback(final_clip, video_file, codec=video_codec, fps=30, logger=None)
            close_clip(clip)
            material.url = video_file
            logger.success(f"image processed: {video_file}")
    return materials